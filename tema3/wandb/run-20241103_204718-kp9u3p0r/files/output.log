
Epoch 1/50
Training: 100%|██████████| 196/196 [01:08<00:00,  2.84batch/s, loss=4.36]
Average Training Loss: 4.4890
Evaluating: 100%|██████████| 40/40 [00:04<00:00,  9.62batch/s, accuracy=2.96]
Validation Accuracy: 2.96%

Epoch 2/50
Training:  53%|█████▎    | 104/196 [00:26<00:23,  3.94batch/s, loss=4.4] 
Traceback (most recent call last):
  File "C:\Users\dando\Documents\GitHub\Capitole-Avansate-Retele-Neuronale\tema3\train.py", line 240, in <module>
    main()
  File "C:\Users\dando\Documents\GitHub\Capitole-Avansate-Retele-Neuronale\tema3\train.py", line 236, in main
    run_training(config, config['sweep']['enabled'])
  File "C:\Users\dando\Documents\GitHub\Capitole-Avansate-Retele-Neuronale\tema3\train.py", line 197, in run_training
    avg_loss = train_one_epoch(model, train_loader, optimizer, device, scaler, other_augmentation)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\Documents\GitHub\Capitole-Avansate-Retele-Neuronale\tema3\train.py", line 124, in train_one_epoch
    for batch in tbar:
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\datasets\cifar.py", line 119, in __getitem__
    img = self.transform(img)
          ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\transforms.py", line 683, in forward
    return F.crop(img, i, j, h, w)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\functional.py", line 551, in crop
    return F_pil.crop(img, top, left, height, width)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\_functional_pil.py", line 235, in crop
    return img.crop((left, top, left + width, top + height))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\PIL\Image.py", line 1302, in crop
    return self._new(self._crop(self.im, box))
                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\PIL\Image.py", line 1320, in _crop
    absolute_values = (abs(x1 - x0), abs(y1 - y0))
                       ^^^^^^^^^^^^
KeyboardInterrupt
