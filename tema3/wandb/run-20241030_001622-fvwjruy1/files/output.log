
Epoch 1/5
Training:  49%|████▉     | 383/782 [00:20<00:21, 18.88batch/s, loss=3.72]
Traceback (most recent call last):
  File "C:\Users\dando\Documents\GitHub\Capitole-Avansate-Retele-Neuronale\tema3\train.py", line 125, in <module>
    main()
  File "C:\Users\dando\Documents\GitHub\Capitole-Avansate-Retele-Neuronale\tema3\train.py", line 105, in main
    avg_loss = train_one_epoch(model, train_loader, optimizer, device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\Documents\GitHub\Capitole-Avansate-Retele-Neuronale\tema3\train.py", line 45, in train_one_epoch
    for batch in tbar:
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\datasets\cifar.py", line 119, in __getitem__
    img = self.transform(img)
          ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\transforms.py", line 1280, in forward
    img = F.adjust_hue(img, hue_factor)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\functional.py", line 968, in adjust_hue
    return F_pil.adjust_hue(img, hue_factor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\torchvision\transforms\_functional_pil.py", line 117, in adjust_hue
    img = Image.merge("HSV", (h, s, v)).convert(input_mode)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dando\AppData\Local\Programs\Python\Python312\Lib\site-packages\PIL\Image.py", line 1146, in convert
    im = self.im.convert(mode, dither)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
